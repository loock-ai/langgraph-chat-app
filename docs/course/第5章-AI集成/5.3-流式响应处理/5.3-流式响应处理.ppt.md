---
marp: true
theme: gaia
paginate: true
header: '5.3-流式响应处理'
style: |
  section {
    font-size: 30px;
  }
---

<!-- _class: lead -->
# 第5章 AI集成 🤖

## 5.3 流式响应处理

**实现实时AI对话体验**

---

## 🎯 学习目标

- **理解LangGraphJS中的流式事件系统**
- **掌握streamEvents的使用方法**
- **实现实时的AI对话体验**
- **优化流式响应的性能和用户体验**

让AI对话如丝般顺滑！

---

## 📚 流式事件系统原理

### streamEvents基础用法
```typescript
for await (const event of app.streamEvents(
  { messages: [new HumanMessage('你好')] },
  { version: 'v2', configurable: { thread_id: 'session-1' } }
)) {
  // 处理不同类型的事件
  if (event.event === 'on_chat_model_stream') {
    const chunk = event.data?.chunk;
    if (chunk?.content) {
      console.log(chunk.content); // 实时输出AI回复
    }
  }
}
```

实时获取AI输出，无需等待完整回复！

---

## 🏗️ 核心事件类型

### 重要事件详解
- **`on_chat_model_stream`** - AI模型的流式输出 ⭐
- **`on_chain_start`** - 工作流开始
- **`on_chain_end`** - 工作流结束
- **`on_chain_stream`** - 链式流输出

重点关注 `on_chat_model_stream`，这是实时对话的核心！

---

## 💡 API路由流式实现

```typescript
// app/api/chat/route.ts
export async function POST(request: NextRequest) {
  const { message, threadId } = await request.json();

  const stream = new ReadableStream({
    async start(controller) {
      const encoder = new TextEncoder();
      
      for await (const event of app.streamEvents(
        { messages: [new HumanMessage(message)] },
        { version: 'v2', configurable: { thread_id: threadId } }
      )) {
        if (event.event === 'on_chat_model_stream') {
          const chunk = event.data?.chunk;
          if (chunk?.content) {
            controller.enqueue(encoder.encode(
              JSON.stringify({ type: 'chunk', content: chunk.content }) + '\n'
            ));
          }
        }
      }
      controller.close();
    }
  });

  return new Response(stream);
}
```

---

## 🔗 前端流式数据接收

```typescript
async function sendMessageWithStream(message: string, threadId: string) {
  const response = await fetch('/api/chat', {
    method: 'POST',
    body: JSON.stringify({ message, threadId })
  });

  const reader = response.body?.getReader();
  const decoder = new TextDecoder();

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;

    const chunk = decoder.decode(value);
    const data = JSON.parse(chunk);
    
    if (data.type === 'chunk') {
      // 实时更新界面
      setStreamingContent(prev => prev + data.content);
    }
  }
}
```

---

## 🌟 用户体验优化

### 打字机效果实现
```typescript
// 前端状态管理
const [streamingContent, setStreamingContent] = useState('');
const [isStreaming, setIsStreaming] = useState(false);

// 流式内容更新
if (data.type === 'chunk') {
  setStreamingContent(prev => prev + data.content);
} else if (data.type === 'end') {
  setIsStreaming(false);
}
```

### 视觉效果
- **光标闪烁** - 表示AI正在"思考"
- **逐字显示** - 模拟真实的打字过程
- **加载动画** - 等待响应时的视觉反馈

---

## 🔧 性能优化技巧

### 前端优化策略
```typescript
// 使用buffer避免频繁DOM更新
let buffer = '';
const lines = buffer.split('\n');
buffer = lines.pop() || '';

// 批量处理多行数据
for (const line of lines) {
  if (line.trim()) {
    const data = JSON.parse(line);
    // 处理数据...
  }
}
```

### 错误处理和恢复
- **网络中断检测** - 自动重连机制
- **流中断处理** - 优雅的错误恢复
- **内存管理** - 及时清理完成的流

---

## 🔧 调试和监控

```typescript
// 添加详细的流式事件监控
for await (const event of app.streamEvents(...)) {
  console.log('事件类型:', event.event);
  
  if (event.event === 'on_chat_model_stream') {
    const chunk = event.data?.chunk;
    console.log('内容块长度:', chunk?.content?.length || 0);
    console.log('累计内容:', totalContent.length);
  }
}
```

详细的监控让流式处理更可控！

---

## 📋 总结要点

- **streamEvents系统** - LangGraphJS的强大流式能力
- **事件驱动** - 基于事件的流式数据处理模式
- **实时体验** - 流式响应显著提升用户体验
- **性能优化** - 合理的缓冲和批处理机制
- **错误处理** - 健壮的流式错误处理机制

流式响应让AI对话更有温度！

---

## 🚀 下一步预告

掌握了流式响应处理后，我们将学习：

**5.4 会话和状态管理**
- Thread会话管理机制
- 检查点状态持久化
- 多轮对话状态管理
- 历史记录功能实现

让AI记住每一次对话！
